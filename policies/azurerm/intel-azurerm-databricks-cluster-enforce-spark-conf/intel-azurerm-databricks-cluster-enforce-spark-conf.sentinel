import "tfplan/v2" as tfplan
import "approved"
import "policy_summary"

param valid_actions default [
	["no-op"],
	["create"],
	["update"],
]

doc = {
	"allowed":   null,
	"category":  approved.databricks.databricks_cluster.category,
	"error":     " has no optimization scripts.",
	"file_name": "intel-azurerm-databricks-cluster-enforce-spark-conf.sentinel",
	"md_url":    approved.policies_url.databricks,
	"parameter": "spark_conf",
	"provider":  approved.databricks.databricks_cluster.provider,
	"resource":  approved.databricks.databricks_cluster.resource,
	"violation": "The configured databricks cluster should use optimization scripts",
}

// Filter resources by type
all_resources = filter tfplan.resource_changes as _, rc {
	rc.type is doc.resource and
		rc.mode is "managed" and
		rc.change.actions in valid_actions
}

// Filter resources that violate a given condition
violators = filter all_resources as _, r {
	r.change.after.spark_conf is null
}

// Build a summary report
summaryreport = {
	"name": doc.name,
	"violations": map violators as _, violation {
		{
			"name":    violation.name,
			"address": violation.address,
			"type":    violation.type,
			"message": violation.name + doc.error,
		}
	},
}

# The configured databricks cluster should use optimization scripts
main = rule {
	policy_summary.summary(summaryreport, doc)
}
